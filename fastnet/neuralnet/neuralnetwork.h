/** 
@file  neuralnetwork.h
@brief NeuralNetwork class declaration.
*/

#ifndef NEURALNETWORK_H
#define NEURALNETWORK_H

#include <cmath>
#include <cstring>
#include <vector>
#include <iostream>

#include <mex.h>

#include "fastnet/netdata/netdata.h"
#include "fastnet/defines.h"
#include "fastnet/events/mxhandler.h"
#include "fastnet/reporter/Reporter.h"

using namespace std;


/// Namespace for the C++ Neural Network Toolbox
/**
 @author  Rodrigo Coura Torres (torres@lps.ufrj.br)
 @version  1.0
 @date    14/11/2004

 This namespace contains classes to help develop neural network application
 It contains both classes of training and also classes for data access. Any new 
 functionality related to neural networks must be implemented whithin this namespace.
*/
namespace FastNet
{

  /** 
  @brief    Base class for neural network applications.
  @author    Rodrigo Coura Torres (torres@lps.ufrj.br)
  @version  1.0
  @date    14/11/2004

  This class was developed to help the development of neural network applications.
  Some frequently used methods (like feedforwarding an input, for instance) were already
  implemented, but specific methods which the implementation depends on the training method
  being used are pure virtual, and must be implemented by an inherited class that will
  be responsible for implement the specific algorithm for that training. Even the methods
  already implemented by this superclass are virtual, so, if an application specific
  method must be developed, these implemented method can be easily overrided.
  */
  class NeuralNetwork
  {
    protected:
      
      ///Typedef for pointer to member functions.
      /**
       In order to improve speed, the transfer functions are called 
       by means of function pointers. This typedef makes easy to refer to
       this kind of pointer. In order to work correctly, this typedef MUST be
       declared inside the class which member functions it will refer to.
      */
      typedef  REAL (NeuralNetwork::*TRF_FUNC_PTR)(REAL val, bool deriv) const; 


      /// Holds the range of active nodes in a layer.
      /**
       This struct is used to hold the range (ini and end) of active nodes in 
       a layer. So, ia a layer has 4 nodes, and the init and end values are,
       respectively 0 and 2), only the first 3 nodes will be considered. The
       last one will be ignored by all functions (propagateInput, updateWeights, etc).
      */
      struct NodesRange
      {
        unsigned init;
        unsigned end;
      };

      //Class attributes.

      /// The weights matrix.
      /**
       Stores the weights matrix, where the dimensions (w[x][y][z])are:
        - x: the layer index (where 0 is the first hidden layer).
        - y: the index of the node in layer x.
        - z: the index of the node in layer x-1.
      */
      REAL ***weights;
      

      /// Stores the entwork bias
      /**
       Stores the biases matrix, where the dimensions (b[x][y]) are:
        - x: the layer index (where 0 is the first hidden layer).
        - y: the index of the node in layer x.
      */
      REAL **bias;
      
      
      /// Stores the output generated by each layer.
      /**
       Stores the output generated by each layer. So, the output generated
       by the network is layerOutputs[nLayers-1]. The dimensions (layerOutputs[x][y]) are:
        - x: the layer index (where 0 is the output of the input layer).
        - y: the output generated by the node y in layer x.
      */
      REAL **layerOutputs;
      

      /// Store the number of nodes in each layer (including the input layer).
      /**
      This vector must contains the number of nodes in each layer, including the input layer. So,
      for intance, a network of type 4-3-1, the nNodes will contain the values, 4,3 and 1, respectively.
      It must be exactly the same as the neural network
      being used.
      */
      vector<unsigned> nNodes;


      /// Stores the nodes activation range in each layer.
      /**
       This vector will hold the range of active neurons in each layer.
       For instance, if activeNodes[1].init = 2 and activeNodes[1].end = 4, 
       and nNodes[1] = 8, it means that the nodes 0,1,5,6 and 7 of layer 1 (starting in 0)
       will be completed ignored by the class and any other subclass (as they not even exist).
       Caution must be taken when a new method is created either in this
       class or in any other derived class, in order to correctly implement this
       functionality. By default, all nodes are active. If the user wants to
       set an specific range of active nodes for a layer, he must do so by calling
       the specific methods for that end.
       @see FastNet::NeuralNetwork#setActiveNodes
      */
      vector<NodesRange> activeNodes;


      /// Specifies if a layer is using bias.
      /**
       This vector tells the class and its derived classes which layers are using
       bias, by default, the class starts this vector with "true" for all layers, telling that
       all layers will be using bias, unless the user tells otherwise by calling
       the corresponding function for that.
       @see FastNet::NeuralNetwork#setUsingBias
      */
      vector<bool> usingBias;


      /// Tells which nodes are frozen.
      /**
       This matrix store bolean values that tells if the corresponding
       node is frozen or not. If a node is frozen, the weights connected to
       its input will not be changed. Otherwise, the node works normally.
       By default, the class automatically makes all nodes unfrozen. If the
       user wants to freeze an specific node he must do that by means
       of calling the specific method for this purpuse.
       The dimensions of this matrix are (frozenNode[x][y]):
        - x: the layer index (where 0 is the input layer).
        - y: The node in layer x.
       @see FastNet::NeuralNetwork#setFreeze
      */
      bool **frozenNode;


      /// Vector of pointers to transfer functions.
      /**
       This vector holds, for each layer (where 0 is the first hidden layer)
       a pointer to the transfer function that will be used in that layer.
       Doing so, there is no overhead during network execution, because
       the pointers are already set up before the execution.
      */
      vector<TRF_FUNC_PTR> trfFunc;

      //Inline standart methods.

      /// Hyperbolic tangent transfer function.
      /*
       This method calculates the hyperbolic tangent of a given number, or the
       derivative of a tangent hiperbolic for that value.
       @param[in] val The value which the hyperbolic tangent (or its derivative) must be calculated.
       @param[in] deriv If true, the function will calculate the dervative, otherwise, the hyperbolic tangent value of "val".
       @return The hyperbolic value of "val" (\f$ \tanh(val) \f$), if "deriv" = false, or its derivative \f$1 - val^2\f$ otherwise.
      */
      REAL hyperbolicTangent(REAL val, bool deriv) const {return (deriv) ? (1 - (val*val)) : tanhf(val);};

      
      /// Linear transfer function.
      /*
       This method implements a linear transfer function, or the
       derivative of the linear function for that value.
       @param[in] val The value which the linear function must be calculated.
       @param[in] deriv If true, the function will calculate the dervative, otherwise, the linear value of "val".
       @return "val" ("deriv" = false) or 1 ("deriv" = true).
      */
      REAL linear(REAL val, bool deriv) const {return (deriv) ? 1 : val;};


      /// Releases the memory used by a bias matrix.
      /**
       This method releases the memory dynamically allocated
       for a bias matrix (or any other matrix that has the exactly same size),
       by using the size information of the bias matrix.
       If successfull, the pointer will be assigned to NULL.
       @param b A pointer to a bias matrix.
      */
      void releaseMatrix(REAL **b);
      
      
      /// Releases the memory used by a weight matrix.
      /**
       This method releases the memory dynamically allocated
       for a weight matrix (or any other matrix that has the exactly same size), 
       by using the size information of the weight matrix.
       If successfull, the pointer will be assigned to NULL.
       @param w A pointer to a weight matrix.
      */
      void releaseMatrix(REAL ***w);


      //Dynamically allocates all the memory we need.
      /**
      This function will take the nNodes vector ans will allocate all the memory that must be
      dynamically allocated. Caution: you <b>MUST</b> set, prior to call this function, the
      nNodes vector.
      */
      virtual void allocateSpace();

    public:
      //Virtual methods.


      /// Ramdomly initializes the weight and bias values.
      /**
       This method ramdomly initializes the weight and bias values of a neural
       network.
       @param[in] initWeightRange the weights's range, so that -initWeightRange \f$\leq\f$ w \f$\leq\f$ initWeightRange.
      */
      virtual void initWeights(REAL initWeightRange);
      
      
      /// Specifies the range of active nodes in a specific layer.
      /**
       This function is used to specify the range of active nodes in a specific layer.
       For instance, if activeNodes[1].init = 2 and activeNodes[1].end = 4, 
       and nNodes[1] = 8, it means that only the nodes 2,3 and 4 will be active 
       (nodes 0,1,5,6 and 7 of layer 1 will be ignored)
       @param[in] layer The layer in which the nodes will be activated (0 is the input layer).
       @param[in] initNode The first node in the range of active nodes (where 0 is the first node).
       @param[in] endNode The last node in the range of active nodes (where 0 is the first node).
      */
      void setActiveNodes(unsigned layer, unsigned initNode, unsigned endNode) {activeNodes[layer].init = initNode; activeNodes[layer].end = (endNode+1);}
      
      
      //Set all nodes as active.
      /**
       This method is used to activate all the nodes in the network. It sets
       the range of active nodes to init=0 and end = nNodes[i] (where i is the current layer)
       for all layers.
      */
      void resetActiveNodes(){for (unsigned i=0; i<nNodes.size(); i++) setActiveNodes(i, 0, (nNodes[i]-1));};
      
      
      /// Propagates the input through the network.
      /**
       This method propagates the input data through the network.
       The output of each layer is stored in matrix "layerOutputs".
       @param input  The network's input vector.
       @return A pointer to the network's output (layerOutputs[nNodes.size()-1]).
      */
      virtual const REAL* propagateInput(const REAL *input);

      //Pure virtual methods.

      /// Calculates the new weights and biases update values.
      /**
       This method calculates the weights and biases update values.
       The way these update values are calculated depends on the training 
       being applied to the network. So, the class that inherites this one
       is responsible for the specific implementation of that method.
       @param[in] output The output generated by the neural network.
       @param[in] target The desired output (target).
      */
      virtual void calculateNewWeights(const REAL *output, const REAL *target) = 0;

  
      /// Calculates the new weights and biases update values taking into count the number of events in a pattern.
      /**
       This method calculates the weights and biases update values.
       The way these update values are calculated depends on the training 
       being applied to the network. So, the class that inherites this one
       is responsible for the specific implementation of that method.
       This method must take into count the number of events in each pattern,
       so this method can be able to correctly calculates the new weights
       even if an specific pattern has many less events than the others.
       @param[in] output The output generated by the neural network.
       @param[in] target The desired output (target).
       @param[in] nEv Number of events for the pattern whoose output was generated.
       @param[in] nPat Number of patterns being applied to the neural network.
      */
      virtual void calculateNewWeights(const REAL *output, const REAL *target, unsigned nEv, unsigned nPat) = 0;
      
      /// Updates the neural network's weights and biases.
      /**
       This method, after the updating values have been calculated, update
       the weighjt and biases values. So, the network actually changes it weights
       and biases values only when this method is called. The specific form that
       the weights is going to be updated depends on the class that inherited this
       class and implements this method.

      */
      virtual void updateWeights() = 0;

      //Default methods.

      ///Copy constructor.
      /**
      This constructor should be used to create a new network which is an exactly copy
      of another network.
      @param[in] net The network that we will copy the parameters from.
      */
      NeuralNetwork(const NeuralNetwork &net);

      /// Constructor taking the parameters for a matlab net structure.
      /**
      This constructor should be called when the network parameters are stored in a matlab
      network structure.
      @param[in] netStr The Matlab network structure as returned by newff.
      */
      NeuralNetwork(const mxArray *netStr);
      
      /// Class destructor.
      /**
       Releases all the dynamically allocated memory used by this class.
      */
      virtual ~NeuralNetwork();
      
      /// Gives the neural network information.
      /**
       This method sends to a stream text information about the neural
       network. This method sould be inherited by derived classes from
       this class, in order to give additional information about the
       neural network.
       @param[in] str The stream where the information will be written to.
      */
      virtual void showInfo(ostream &str) const;      


      /// Returns an specific weight value.
      /**
       This method gets a weight value inside the network.
       @param[in] layer The layer where the node which the desired weight values is connected to.
       @param[in] node The index of the node in layer "layer".
       @param[in] prevNode The index of the node in layer "layer-1".
       @return The weight value at the specific location (w[layer][node][prevNode])
      */
      REAL getWeight(unsigned layer, unsigned node, unsigned prevNode) const {return weights[layer][node][prevNode];};
      
      
      /// Returns an specific bias value.
      /**
       This method gets a bias value inside the network.
       @param[in] layer The layer where the node which the desired bias values is connected to.
       @param[in] node The index of the node in layer "layer".
       @return The bias value at the specific location (b[layer][node])
      */
      REAL getBias(unsigned layer, unsigned node) const {return bias[layer][node];};
      
      
      /// Gets the number of layers (including the input layer) of the network.
      /**
       @return The number of layers in the network.
      */
      unsigned getNumLayers() const {return nNodes.size();};


      /// Gets the number of nodes in a specific layer.
      /**
       @param layer The layer which the number of nodes we want to know.
       @return The number of nodes in the layer.
      */
      unsigned operator[](unsigned layer) const {return nNodes[layer];};
      
      
      /// Writes the weights and biases values.
      /**
       This method takes the passed handler and pass these values to that
       handler, so it can store ir according to the class that inherites
       from NetData. The method is implementad that way, so the weights and biases
       are protected from not authorized access, since it can be accessed only by
       classes that inherits from NetData.
       @param[in] data The data handler that will actually store the weights ans biases values.
      */
      void writeWeights(NetData *data) {data->writeWeights(weights, bias);};
      
      
      /// Reads the initial weights and biases from the matlab structure.
      /**
      This method reads the weights and biases values from the matlab environment passed.
      @param[in] mNet The Matlab network structure from where to read the weights and biases.
      */
      void readWeights(const mxArray *mNet);

      
      /// Sets the freeze/unfreeze status of an specific node.
      /**
       Thos methods sets the freeze status of an specific node. If a node is frozen,
       the weights connected to its input are not changed.
       @param[in] layer The layer where the node to be set as frozen/unfrozen is (where 0 is the first hidden layer).
       @param[in] node The index of the node.
       @param[in] freezed If true, the node is set as freezed, otherwise it is set as unfreezed.
      */
      void setFrozen(unsigned layer, unsigned node, bool frozen)
      {
        frozenNode[layer][node] = frozen;
        DEBUG1("frozenNode["<< layer << "]["<< node << "] = "<< frozen);
      };

      
      /// Sets the frozen/unfrozen status of an entire layer.
      /**
       Thos methods sets the freeze status for all the nodes in a specific layer. 
       If a node is frozen, the weights connected to its input are not changed.
       @param[in] layer The layer where the nodes to be set as freeze/unfreeze are (where 0 is the first hidden layer).
       @param[in] freezed If true, the node is set as freezed, otherwise it is set as unfreezed.
      */
      void setFrozen(unsigned layer, bool frozen){for (unsigned i=0; i<nNodes[layer+1]; i++) setFrozen(layer, i, frozen);};
      
      
      /// Tells if a node is frozen or not.
      /**
       param[in] layer The layer where the node frozen status is (where 0 is the first hidden layer).
       param[in] node The index of the node in the layer.
       @return True if the node is frozen, false otherwise.
      */
      bool isFrozen(unsigned layer, unsigned node) const {return frozenNode[layer][node];};
      
      
      /// Tells if an entire layer is frozen.
      /**
       This method checks if all the active nodes of an specific layer are frozen or not.
       param[in] layer The layer to be checked (where 0 is the first hidden layer).
       @return True if all nodes are frozen, false if one or more nodes are unfrozen.
      */
      bool isFrozen(unsigned layer) const;


      /// Defrost all nodes in the network.
      /**
       This method goes through the network and unfrost every node in each.
      */
      void defrostAll(){for (unsigned i=0; i<(nNodes.size()-1); i++) setFrozen(i, false);};


      /// Sets if an specific layer will use or not bias.
      /**
       This method specifies of an specific layer will, or will not, use bias.
       If bias is not being used in a specific layer, all the biases values
       are set to zero, but if bias use is enable, no modification on the values are made.
       @param[in] layer The layer we want to set the use or not of bias (where 0 is the first hidden layer).
       @param[in] val If true, the layer will use bias, false otherwise.
      */
      void setUsingBias(const unsigned layer, const bool val);
      
      
      /// Sets if the network will use or not bias.
      /**
       This method specifies if the network will, or will not, use bias.
       @param[in] val If true, all layers in the network will use bias, false otherwise.
      */
      void setUsingBias(const bool val) {for (unsigned i=0; i<(nNodes.size()-1); i++) setUsingBias(i, val);};
      
      
      /// Gets if an specific layer is using bias.
      /**
       @param[in] layer The layer we want to know if it is using bias.
       @return True if bias is being used, false otherwise.
      */
      bool isUsingBias(const unsigned layer) const {return usingBias[layer];};


      /// Propagates and input event and calculates the MSE error obtained by comparing to a target output.
      /**
       This method should be used only in supervised
       training algorithms. It propagates an input through the network, and, after 
       comparing the output generated with the desired (target) output, calculates
       the MSE error obtained by the relation below:
       
       \f$ e = \frac{1}{N} \sum\limits_{i=0}^{N-1} \left ( t[i] - o[i] \right )^2 \f$

       where:
        - N is the number of nodes in the output layer.
        - o[i] is the output generated by the network at the ith node.
        - t[i] is the desired output to the ith node.

       @param[in] input The vector containing the input to be presented to the network.
       @param[in] target The vector containing the desired output (target) of the network.
       @param[out] output This pointer will point to the output generated by the network. It must
       not be deallocated after use. The class will automatically release the memory used by
       this vector.
       @return The MSE error calculated.
      */
      virtual REAL applySupervisedInput(const REAL *input, const REAL *target, const REAL* &output);


      /// Flush weights from memory to a Matlab variable.
      /**
       Since this class, in order to optimize speed, saves the
       weights and bias values into memory, at the end, if the user wants
       to save the final values, this method must be called. It will
       save the weights and biases values stored in the memory buffer in a matlab variable.
       So, this method can only be used after the writeWeights has been called at least once.
       @param[out] outNet The matlab network structure to where the weights and biases will be saved to.
      */
      void flushBestTrainWeights(mxArray *outNet) const;
  };
}

#endif
