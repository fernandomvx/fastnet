/** 
@file  neuralnetwork.h
@brief NeuralNetwork class declaration.
*/

#ifndef NEURALNETWORK_H
#define NEURALNETWORK_H

#include <cmath>
#include <cstring>
#include <vector>
#include <iostream>

#include <mex.h>

#include "fastnet/defines.h"
#include "fastnet/matlab/mxhandler.h"
#include "fastnet/reporter/Reporter.h"

using namespace std;


/// Namespace for the C++ Neural Network Toolbox
/**
 @author  Rodrigo Coura Torres (torres@lps.ufrj.br)
 @version  1.0
 @date    14/11/2004

 This namespace contains classes to help develop neural network application
 It contains both classes of training and also classes for data access. Any new 
 functionality related to neural networks must be implemented whithin this namespace.
*/
namespace FastNet
{

  /** 
  @brief    Base class for neural network applications.
  @author    Rodrigo Coura Torres (torres@lps.ufrj.br)
  @version  1.0
  @date    14/11/2004

  This class was developed to help the development of neural network applications.
  Some frequently used methods (like feedforwarding an input, for instance) were already
  implemented, but specific methods which the implementation depends on the training method
  being used are pure virtual, and must be implemented by an inherited class that will
  be responsible for implement the specific algorithm for that training. Even the methods
  already implemented by this superclass are virtual, so, if an application specific
  method must be developed, these implemented method can be easily overrided.
  */
  class NeuralNetwork
  {
    protected:
      
      ///Typedef for pointer to member functions.
      /**
       In order to improve speed, the transfer functions are called 
       by means of function pointers. This typedef makes easy to refer to
       this kind of pointer. In order to work correctly, this typedef MUST be
       declared inside the class which member functions it will refer to.
      */
      typedef  REAL (NeuralNetwork::*TRF_FUNC_PTR)(REAL val, bool deriv) const; 


      /// Holds the range of active nodes in a layer.
      /**
       This struct is used to hold the range (ini and end) of active nodes in 
       a layer. So, ia a layer has 4 nodes, and the init and end values are,
       respectively 0 and 2), only the first 3 nodes will be considered. The
       last one will be ignored by all functions (propagateInput, updateWeights, etc).
      */
      struct NodesRange
      {
        unsigned init;
        unsigned end;
      };

      //Class attributes.

      /// The weights matrix.
      /**
       Stores the weights matrix, where the dimensions (w[x][y][z])are:
        - x: the layer index (where 0 is the first hidden layer).
        - y: the index of the node in layer x.
        - z: the index of the node in layer x-1.
      */
      REAL ***weights;
      

      /// Stores the network bias
      /**
       Stores the biases matrix, where the dimensions (b[x][y]) are:
        - x: the layer index (where 0 is the first hidden layer).
        - y: the index of the node in layer x.
      */
      REAL **bias;

      /// Stores the output generated by each layer.
      /**
       Stores the output generated by each layer. So, the output generated
       by the network is layerOutputs[nLayers-1]. The dimensions (layerOutputs[x][y]) are:
        - x: the layer index (where 0 is the output of the input layer).
        - y: the output generated by the node y in layer x.
      */
      REAL **layerOutputs;
      

      /// Store the number of nodes in each layer (including the input layer).
      /**
      This vector must contains the number of nodes in each layer, including the input layer. So,
      for intance, a network of type 4-3-1, the nNodes will contain the values, 4,3 and 1, respectively.
      It must be exactly the same as the neural network
      being used.
      */
      vector<unsigned> nNodes;


      /// Stores the nodes activation range in each layer.
      /**
       This vector will hold the range of active neurons in each layer.
       For instance, if activeNodes[1].init = 2 and activeNodes[1].end = 4, 
       and nNodes[1] = 8, it means that the nodes 0,1,5,6 and 7 of layer 1 (starting in 0)
       will be completed ignored by the class and any other subclass (as they not even exist).
       Caution must be taken when a new method is created either in this
       class or in any other derived class, in order to correctly implement this
       functionality. By default, all nodes are active. If the user wants to
       set an specific range of active nodes for a layer, he must do so by calling
       the specific methods for that end.
       @see FastNet::NeuralNetwork#setActiveNodes
      */
      vector<NodesRange> activeNodes;


      /// Specifies if a layer is using bias.
      /**
       This vector tells the class and its derived classes which layers are using
       bias, by default, the class starts this vector with "true" for all layers, telling that
       all layers will be using bias, unless the user tells otherwise by calling
       the corresponding function for that.
       @see FastNet::NeuralNetwork#setUsingBias
      */
      vector<bool> usingBias;


      /// Vector of pointers to transfer functions.
      /**
       This vector holds, for each layer (where 0 is the first hidden layer)
       a pointer to the transfer function that will be used in that layer.
       Doing so, there is no overhead during network execution, because
       the pointers are already set up before the execution.
      */
      vector<TRF_FUNC_PTR> trfFunc;

      //Inline standart methods.

      /// Hyperbolic tangent transfer function.
      /*
       This method calculates the hyperbolic tangent of a given number, or the
       derivative of a tangent hiperbolic for that value.
       @param[in] val The value which the hyperbolic tangent (or its derivative) must be calculated.
       @param[in] deriv If true, the function will calculate the dervative, otherwise, the hyperbolic tangent value of "val".
       @return The hyperbolic value of "val" (\f$ \tanh(val) \f$), if "deriv" = false, or its derivative \f$1 - val^2\f$ otherwise.
      */
      REAL hyperbolicTangent(REAL val, bool deriv) const {return (deriv) ? (1 - (val*val)) : tanhf(val);};

      
      /// Linear transfer function.
      /*
       This method implements a linear transfer function, or the
       derivative of the linear function for that value.
       @param[in] val The value which the linear function must be calculated.
       @param[in] deriv If true, the function will calculate the dervative, otherwise, the linear value of "val".
       @return "val" ("deriv" = false) or 1 ("deriv" = true).
      */
      REAL linear(REAL val, bool deriv) const {return (deriv) ? 1 : val;};


      /// Releases the memory used by a bias matrix.
      /**
       This method releases the memory dynamically allocated
       for a bias matrix (or any other matrix that has the exactly same size),
       by using the size information of the bias matrix.
       If successfull, the pointer will be assigned to NULL.
       @param b A pointer to a bias matrix.
      */
      void releaseMatrix(REAL **b);
      
      
      /// Releases the memory used by a weight matrix.
      /**
       This method releases the memory dynamically allocated
       for a weight matrix (or any other matrix that has the exactly same size), 
       by using the size information of the weight matrix.
       If successfull, the pointer will be assigned to NULL.
       @param w A pointer to a weight matrix.
      */
      void releaseMatrix(REAL ***w);


      //Dynamically allocates all the memory we need.
      /**
      This function will take the nNodes vector ans will allocate all the memory that must be
      dynamically allocated. Caution: you <b>MUST</b> set, prior to call this function, the
      nNodes vector.
      */
      virtual void allocateSpace(const vector<unsigned> &nNodes);
      
      /// Reads the initial weights and biases from the matlab structure.
      /**
      This method reads the weights and biases values from the matlab environment passed.
      @param[in] mNet The Matlab network structure from where to read the weights and biases.
      */
      void readWeights(const mxArray *mNet);

    public:
      //Virtual methods.      
      
      /// Specifies the range of active nodes in a specific layer.
      /**
       This function is used to specify the range of active nodes in a specific layer.
       For instance, if activeNodes[1].init = 2 and activeNodes[1].end = 4, 
       and nNodes[1] = 8, it means that only the nodes 2,3 and 4 will be active 
       (nodes 0,1,5,6 and 7 of layer 1 will be ignored)
       @param[in] layer The layer in which the nodes will be activated (0 is the input layer).
       @param[in] initNode The first node in the range of active nodes (where 0 is the first node).
       @param[in] endNode The last node in the range of active nodes (where 0 is the first node).
      */
      void setActiveNodes(unsigned layer, unsigned initNode, unsigned endNode) {activeNodes[layer].init = initNode; activeNodes[layer].end = (endNode+1);}
      
      
      //Set all nodes as active.
      /**
       This method is used to activate all the nodes in the network. It sets
       the range of active nodes to init=0 and end = nNodes[i] (where i is the current layer)
       for all layers.
      */
      void resetActiveNodes(){for (unsigned i=0; i<nNodes.size(); i++) setActiveNodes(i, 0, (nNodes[i]-1));};
      
      
      /// Propagates the input through the network.
      /**
       This method propagates the input data through the network.
       The output of each layer is stored in matrix "layerOutputs".
       @param input  The network's input vector.
       @return A pointer to the network's output (layerOutputs[nNodes.size()-1]).
      */
      virtual const REAL* propagateInput(const REAL *input);

      //Pure virtual methods.


      /// Returns a clone of the object.
      /**
      Returns a clone of the calling object. The clone is dynamically allocated,
      so it must be released with delete at the end of its use.
      @return A dynamically allocated clone of the calling object.
      */
      virtual NeuralNetwork *clone()=0;

      //Default methods.

      ///Copy constructor.
      /**
      This constructor should be used to create a new network which is an exactly copy
      of another network.
      @param[in] net The network that we will copy the parameters from.
      */
      NeuralNetwork(const NeuralNetwork &net);

      /// Constructor taking the parameters for a matlab net structure.
      /**
      This constructor should be called when the network parameters are stored in a matlab
      network structure.
      @param[in] netStr The Matlab network structure as returned by newff.
      */
      NeuralNetwork(const mxArray *netStr);
            
      /// Class destructor.
      /**
       Releases all the dynamically allocated memory used by this class.
      */
      virtual ~NeuralNetwork();
      
      /// Gives the neural network information.
      /**
       This method sends to a stream text information about the neural
       network. This method sould be inherited by derived classes from
       this class, in order to give additional information about the
       neural network.
       @param[in] str The stream where the information will be written to.
      */
      virtual void showInfo(ostream &str) const;

      //Copy the status from the passing network.
      /**
        This method will make a deep copy of all attributes from the passing network,
        making them exactly equal. This method <b>does not</b> allocate any memory for
        the calling object. The space for weights and bias info must have been previously created.
        @param[in] net The network from where to copy the data from.
      */
      virtual void operator=(const NeuralNetwork &net);

      /// Returns an specific weight value.
      /**
       This method gets a weight value inside the network.
       @param[in] layer The layer where the node which the desired weight values is connected to.
       @param[in] node The index of the node in layer "layer".
       @param[in] prevNode The index of the node in layer "layer-1".
       @return The weight value at the specific location (w[layer][node][prevNode])
      */
      REAL getWeight(unsigned layer, unsigned node, unsigned prevNode) const {return weights[layer][node][prevNode];};
      
      
      /// Returns an specific bias value.
      /**
       This method gets a bias value inside the network.
       @param[in] layer The layer where the node which the desired bias values is connected to.
       @param[in] node The index of the node in layer "layer".
       @return The bias value at the specific location (b[layer][node])
      */
      REAL getBias(unsigned layer, unsigned node) const {return bias[layer][node];};
      
      
      /// Gets the number of layers (including the input layer) of the network.
      /**
       @return The number of layers in the network.
      */
      unsigned getNumLayers() const {return nNodes.size();};


      /// Gets the number of nodes in a specific layer.
      /**
       @param layer The layer which the number of nodes we want to know.
       @return The number of nodes in the layer.
      */
      unsigned operator[](unsigned layer) const {return nNodes[layer];};

      /// Sets if an specific layer will use or not bias.
      /**
       This method specifies of an specific layer will, or will not, use bias.
       If bias is not being used in a specific layer, all the biases values
       are set to zero, but if bias use is enable, no modification on the values are made.
       @param[in] layer The layer we want to set the use or not of bias (where 0 is the first hidden layer).
       @param[in] val If true, the layer will use bias, false otherwise.
      */
      void setUsingBias(const unsigned layer, const bool val);
      
      
      /// Sets if the network will use or not bias.
      /**
       This method specifies if the network will, or will not, use bias.
       @param[in] val If true, all layers in the network will use bias, false otherwise.
      */
      void setUsingBias(const bool val) {for (unsigned i=0; i<(nNodes.size()-1); i++) setUsingBias(i, val);};
      
      
      /// Gets if an specific layer is using bias.
      /**
       @param[in] layer The layer we want to know if it is using bias.
       @return True if bias is being used, false otherwise.
      */
      bool isUsingBias(const unsigned layer) const {return usingBias[layer];};
  };
}

#endif
